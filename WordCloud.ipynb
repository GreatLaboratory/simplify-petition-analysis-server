{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 분석기별 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from konlpy.tag import Mecab, Kkma, Komoran, Hannanum, Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = '모 기관의 재판 개입과 변호사 사찰을 중단시켜 주세요 대한민국이  공산국가인가요? 취득세 중과제도를 폐지해주세요 지방자치 역행하는 현직시장 더불어민주당 지역위원장 철회를 청원합니다. 계엄령을 선포해 주십시요 입법기관도 이제 못믿겠습니다! 공수처장은 국민투표로 선출 할수있게 해주세요 코로나 돌파구 허경영에게 배워 공수처법을 반대합니다. 국민이 호구인가요? (공매도 폐지, 공평한 양도세 과세 요청) 검찰은 전관예우 말고 뇌물수뢰범죄를 수사하라. 북한이 사살한  공무원 국정조사  해주세요. 거짓말 탄로나자 기억 안 난다는 추미애 법무장관  그런 상태론 법무장관직 수행 불가합니다 김원웅 광복회장 부(김근수),모(전월선) 가짜독립운동가 의혹 진상조사 청원 인권유린판사 최창훈 판사 탄핵추진 청원 가정이 있는 시민에게  새벽 1시경 협박전화한 a모 구미시의원에 대해 청원합니다! 부동산폭등 원흉 김현미 국토부장관 즉각 해임하십시오 소위 塵人 조은산 왈 이른바 시무7조에 대한 교시 행안위 국회의원에 대한 경찰의 봐주기 수사를 엄단해야 합니다! 경기도의 공정세상이 뭔가 이상하네요 투표는 국민 주권의 상징입니다 재검표 부탁드립니다 폐하 이제 그만 양위하시옵소서 애국가 교체 반대와 광복회장의 퇴임 청원 문재인 대통령님 국민을 편가르기 하시려면 이제 본래의 직업 변호사로 돌아 가세요!  내편만 생각하신다면 변호사 직업이 최고의 직업입니다. 윤창호법 강력 적용 안 하는 판사들 규탄 - 6살 아이 사망 사건 더불어민주당 이진련시의원의 갑질을 고발합니다. 류경기 중랑구청장과의 면담을 통해 더불어민주당 독재를 고발합니다 법무부 장관을 사퇴를 시키든 해임을 시키든 대통령이 나서세요!!!!! 불법 레고랜드 강행한 정만호의 국민소통수석 임명을 반대합니다. 반정부 쿠데타 드라이브스루 집회를 허용한 유환우 부장판사를 영구제명해주세요 소규모 드라이브스루집회 허가해준 이성용부장판사 탄핵청원 가짜뉴스•선동뉴스에 대한「징벌적손해배상제도」관련법안 국회통과를 더욱 서둘러야 합니다. 코로나 보다 더 무서운 불법과 비리. 동부지검 특검조사 부탁드립니다 상가 임대차법은 위헌입니다 !! 문재인 대통령님 스스로 하야 해주세요 대통령 공약마저 파기하는 무능한 김현미 국토부 장관을 경질해 주세요 방역방해 ** 집단 ‘국민의힘’(구. 미래통합당) 해산을 청원합니다 절망에 빠진 청년과 미래세대를 구렁텅이에서 구해 주십시요 재검표는 대법원의 고유 권한이다 판사집단을 괴물로 키운 2003년 판사 면책특권 판례의 개정을 청원합니다. 문재인 대통령님,가수 ***씨 폭행 사건 다시 수사해주세요 .ㅠ 재검표 조속히 실시하라 화성시장 서철모 시장직 박탈과 더불어민주당 퇴출을 청원합니다. 헌재는 신속히 법관에게 면책특권을 부여한 판례가 ‘위헌 무효’임을 확인하라!! 국회의원의 계속 재임 임기를 2기(8년)로 제한할 것을 청원합니다. 대한민국에서 가장 큰 특권을 누리는 집단은 사법부이고, 그 특권은 국가 최고규범인 헌법에 어긋나는 것이므로, 신속히 폐지되어야 합니다!! 판사집단을 괴물로 키운 2003년 위헌 판례 변경 2탄 김종인 의원님  신원식의원님  해임해주세요   그리고 문재인대통령님을  처벌해 달라고  미국에 청원한사람을 처벌해주세요 무단으로 공익제보자의 실명을 공개한 황희의원의  국회의원 자격을 박탈해주세요 대한민국은 민주주의 국가이며 법치국가입니다. 김어준을 지킵시다 여론조사 기관  국정조사 요구 문재인 대통령은 국민에게 사죄하고 즉시 하야해라 ‘전관예우’ ‘유전무죄’ 재판을 가능하게 하는 대법원 판례(대법원 2003. 7. 11.ﾠ선고 99다24218 판결)를 없애라!! 펭수를 비롯한 불필요한 참고인 신청을 철회해주세요 기본소득제, 선택이 아닌 필수입니다. 미래통합당 정당 해체를 청원합니다 수천억대 일가 비리 의혹 국민의짐 박덕흠 의원, 특검 실시하십시오! 국민은 괴기한 판결을 한 김미리 판사를 파면한다 검경수사권 세부조정안 담은 대통령령안을 대폭 수정해주십시오 권력의 연구자 탄압을 중지하여 주십시오 한국철도공사 충북본부 폐지를 결사 반대합니다 추미애 장관님 검찰수사관을 채용하지 않겠다는 말씀 다시 한번 생각해 주시기 바랍니다!!! 국회의원 특권을 폐지해야 합니나 박병석 국회의장의 의장직 사퇴를 민주당과 박 의장 본인에게 강력히 요구합니다. ‘사학비리’. 공익제보 하지마세요... 신분보장조치는 뒷전!!!... 공수처와 특별재판부를 만들어주세요 온라인 포탈 기사 작성후 변조/삭제를 금지하고 추가만 가능하도록 제도화 부탁합니다. 사법부출신 국회의원전원이 현직에있을당시의 수사재판변론기록 일체에 대해서 국민의 알 권리를 위하여 인터넷상에 한건도 빠짐없이 공개하라 개풀 뜯어먹는 개소리의 논리, 오랜 특권층 보호만을 위한 모순덩어리 악법 변호사법제109조를 폐지하여 주세요.(폐지 의안발의 요청) '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Kkma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nouns_kkma(txt):\n",
    "    txt = re.sub('[-=.#/!*?:$}]', '', txt)\n",
    "    tokenizer = Kkma()\n",
    "    nouns = tokenizer.nouns(txt)\n",
    "    for i,v in enumerate(nouns):\n",
    "        if len(v) < 2:\n",
    "            nouns.pop(i)\n",
    "    count = Counter(nouns)\n",
    "    noun_list = count.most_common(50)  # 빈도수 기준 조정\n",
    "    return noun_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('조', 2),\n",
       " ('경기', 2),\n",
       " ('가정', 1),\n",
       " ('시민', 1),\n",
       " ('새벽', 1),\n",
       " ('1시경', 1),\n",
       " ('시경', 1),\n",
       " ('협박', 1),\n",
       " ('협박전화', 1),\n",
       " ('전화', 1),\n",
       " ('구미', 1),\n",
       " ('구미시', 1),\n",
       " ('구미시의원', 1),\n",
       " ('의원', 1),\n",
       " ('청원', 1),\n",
       " ('부동산', 1),\n",
       " ('부동산폭등', 1),\n",
       " ('폭등', 1),\n",
       " ('원흉', 1),\n",
       " ('김현미', 1),\n",
       " ('현미', 1),\n",
       " ('국토', 1),\n",
       " ('국토부장관', 1),\n",
       " ('장관', 1),\n",
       " ('해임', 1),\n",
       " ('조은', 1),\n",
       " ('조은산', 1),\n",
       " ('시무', 1),\n",
       " ('시무7조', 1),\n",
       " ('교시', 1),\n",
       " ('행안위', 1),\n",
       " ('위', 1),\n",
       " ('국회의원', 1),\n",
       " ('경찰의', 1),\n",
       " ('수사', 1),\n",
       " ('엄단', 1),\n",
       " ('경기도', 1),\n",
       " ('공정', 1),\n",
       " ('공정세상', 1),\n",
       " ('세상', 1),\n",
       " ('이상', 1),\n",
       " ('투표', 1),\n",
       " ('국민', 1),\n",
       " ('주권', 1),\n",
       " ('상징', 1),\n",
       " ('검표', 1),\n",
       " ('부탁', 1),\n",
       " ('부탁드립', 1),\n",
       " ('드립', 1),\n",
       " ('폐하', 1)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nouns_kkma(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Komoran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nouns_komo(txt):\n",
    "    txt = re.sub('[-=.#*/!?:$}]', '', txt)\n",
    "    tokenizer = Komoran()\n",
    "    nouns = tokenizer.nouns(txt)\n",
    "    for i,v in enumerate(nouns):\n",
    "        if len(v) < 2:\n",
    "            nouns.pop(i)\n",
    "    count = Counter(nouns)\n",
    "    noun_list = count.most_common(50)  # 빈도수 기준 조정\n",
    "    return noun_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('청원', 22),\n",
       " ('국민', 17),\n",
       " ('대통령', 13),\n",
       " ('국회의원', 12),\n",
       " ('판사', 10),\n",
       " ('문재인', 9),\n",
       " ('의원', 8),\n",
       " ('폐지', 8),\n",
       " ('반대', 8),\n",
       " ('처벌', 8),\n",
       " ('요청', 7),\n",
       " ('집회', 7),\n",
       " ('장관', 6),\n",
       " ('코로나', 6),\n",
       " ('조사', 6),\n",
       " ('공수', 5),\n",
       " ('보수', 5),\n",
       " ('위헌', 5),\n",
       " ('고발', 5),\n",
       " ('조은', 4),\n",
       " ('시무', 4),\n",
       " ('특권', 4),\n",
       " ('국회', 4),\n",
       " ('사퇴', 4),\n",
       " ('요구', 4),\n",
       " ('제도', 4),\n",
       " ('재판', 4),\n",
       " ('기관', 4),\n",
       " ('더불어민주당', 4),\n",
       " ('국가', 4),\n",
       " ('탄핵', 4),\n",
       " ('판례', 4),\n",
       " ('집단', 4),\n",
       " ('국토부', 3),\n",
       " ('해임', 3),\n",
       " ('수사', 3),\n",
       " ('경기도', 3),\n",
       " ('재검', 3),\n",
       " ('부탁', 3),\n",
       " ('의장', 3),\n",
       " ('비리', 3),\n",
       " ('변호사', 3),\n",
       " ('대한민국', 3),\n",
       " ('시장', 3),\n",
       " ('임명', 3),\n",
       " ('광복절', 3),\n",
       " ('특검', 3),\n",
       " ('지원', 3),\n",
       " ('삭감', 3),\n",
       " ('하야', 3)]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nouns_komo(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Hannanum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nouns_han(txt):\n",
    "    txt = re.sub('[-=.#/*!?:$}]', '', txt)\n",
    "    tokenizer = Hannanum()\n",
    "    nouns = tokenizer.nouns(txt)\n",
    "    for i,v in enumerate(nouns):\n",
    "        if len(v) < 2:\n",
    "            nouns.pop(i)\n",
    "    count = Counter(nouns)\n",
    "    noun_list = count.most_common(50)  # 빈도수 기준 조정\n",
    "    return noun_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('청원', 10),\n",
       " ('국민', 6),\n",
       " ('더불어민주당', 4),\n",
       " ('반대', 4),\n",
       " ('국회의원', 4),\n",
       " ('문재', 4),\n",
       " ('변호사', 3),\n",
       " ('대한민국', 3),\n",
       " ('수사', 3),\n",
       " ('판사', 3),\n",
       " ('재검표', 3),\n",
       " ('대통령님', 3),\n",
       " ('직업', 3),\n",
       " ('대통령', 3),\n",
       " ('판례', 3),\n",
       " ('특권', 3),\n",
       " ('기관', 2),\n",
       " ('재판', 2),\n",
       " ('철회', 2),\n",
       " ('요청', 2),\n",
       " ('국정조사', 2),\n",
       " ('추미애', 2),\n",
       " ('광복회장', 2),\n",
       " ('의혹', 2),\n",
       " ('김현미', 2),\n",
       " ('해임', 2),\n",
       " ('생각', 2),\n",
       " ('고발', 2),\n",
       " ('장관', 2),\n",
       " ('사퇴', 2),\n",
       " ('불법', 2),\n",
       " ('위헌', 2),\n",
       " ('집단', 2),\n",
       " ('미래통합당', 2),\n",
       " ('대법원', 2),\n",
       " ('판사집단', 2),\n",
       " ('괴물', 2),\n",
       " ('2003년', 2),\n",
       " ('면책특권', 2),\n",
       " ('실시', 2),\n",
       " ('박탈', 2),\n",
       " ('처벌', 2),\n",
       " ('공개', 2),\n",
       " ('요구', 2),\n",
       " ('가능', 2),\n",
       " ('판결', 2),\n",
       " ('개입', 1),\n",
       " ('사찰', 1),\n",
       " ('중단', 1),\n",
       " ('공산국가', 1)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nouns_han(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nouns_okt(txt):\n",
    "    txt = re.sub('[-=.#/*!?:$}]', '', txt)\n",
    "    tokenizer = Okt()\n",
    "    nouns = tokenizer.nouns(txt)\n",
    "    for i,v in enumerate(nouns):\n",
    "        if len(v) < 2:\n",
    "            nouns.pop(i)\n",
    "    count = Counter(nouns)\n",
    "    noun_list = count.most_common(50)  # 빈도수 기준 조정\n",
    "    return noun_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('청원', 22),\n",
       " ('국민', 16),\n",
       " ('대통령', 13),\n",
       " ('국회의원', 12),\n",
       " ('판사', 10),\n",
       " ('문재인', 9),\n",
       " ('폐지', 8),\n",
       " ('집회', 8),\n",
       " ('반대', 8),\n",
       " ('처벌', 8),\n",
       " ('의원', 7),\n",
       " ('요청', 7),\n",
       " ('장관', 6),\n",
       " ('민주당', 6),\n",
       " ('코로나', 6),\n",
       " ('대해', 5),\n",
       " ('시무', 5),\n",
       " ('대한', 5),\n",
       " ('재판', 5),\n",
       " ('고발', 5),\n",
       " ('이제', 4),\n",
       " ('특권', 4),\n",
       " ('사퇴', 4),\n",
       " ('요구', 4),\n",
       " ('제도', 4),\n",
       " ('국가', 4),\n",
       " ('관련', 4),\n",
       " ('탄핵', 4),\n",
       " ('위헌', 4),\n",
       " ('판례', 4),\n",
       " ('집단', 4),\n",
       " ('국토부', 3),\n",
       " ('해임', 3),\n",
       " ('수사', 3),\n",
       " ('경기도', 3),\n",
       " ('검표', 3),\n",
       " ('비리', 3),\n",
       " ('발의', 3),\n",
       " ('변호사', 3),\n",
       " ('대한민국', 3),\n",
       " ('시장', 3),\n",
       " ('임명', 3),\n",
       " ('광복절', 3),\n",
       " ('특검', 3),\n",
       " ('지원', 3),\n",
       " ('삭감', 3),\n",
       " ('하야', 3),\n",
       " ('사건', 3),\n",
       " ('불법', 3),\n",
       " ('조사', 3)]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nouns_okt(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가장 명사를 명확히 추출하고, 불완전한 문장 속에서 해당 명사의 등장 빈도를 정확히 계산한다는 점에서 Komoran과 Okt가 높은 성능을 보임.\n",
    "\n",
    "두 분석기 중 불필요한 조사의 등장이 더 적은 Komoran을 최종 형태소 분석기로 채택함."
   ]
  },
  {
   "source": [
    "## 2. WordCloud - 최종 Komoran"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stop_words: 불용어를 지정해 태스크 목표에 맞지 않는 용어는 사전 제거함\n",
    "\n",
    "get_nouns: 국민청원제목에 해당하는 raw data에서 명사를 추출해, 그 중 가장 많이 등장한 50개 단어를 나열함(최종 채택된 Komoran 사용)\n",
    "\n",
    "visualize: 워드클라우드를 통해 주목받는 국민청원 키워드를 시각화함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\"이제\", \"대해\", \"관련\", \"다시\", \"하라\", \"시오\", \"대한\", \"위해\",\n",
    "                  \"및\", \"두기\", \"저희\", \"제발\", \"바로\", \"동안\", \"정말\", \"경우\", \"제대로\", \"당장\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nouns(txt):\n",
    "    txt = re.sub('[-=.*#/!?:$}]', '', txt)\n",
    "    tokenizer = Komoran()\n",
    "    nouns = tokenizer.nouns(txt)\n",
    "    result = []\n",
    "    for w in nouns: \n",
    "        if w not in stop_words: \n",
    "            result.append(w)\n",
    "    for i,v in enumerate(result):\n",
    "        if len(v) < 2:\n",
    "            result.pop(i)\n",
    "    count = Counter(result)\n",
    "    noun_list = count.most_common(50)  # 빈도수 기준 조정\n",
    "    return noun_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(noun_list):\n",
    "    wc = WordCloud(font_path = \"./font/A옛날목욕탕L.TTF\",\n",
    "                  background_color = 'white', width=1000, height =1000, max_words= 100,max_font_size= 300)\n",
    "    wc.generate_from_frequencies(dict(noun_list))\n",
    "    return wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = get_nouns(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x2cc98b967c8>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 카테고리별 WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input: csv 형식의 데이터프레임\n",
    "\n",
    "output: 디렉토리에 국민청원 카테고리별 워드클라우드 결과가 png 형식으로 저장됨(총 17개)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./category_title.csv\",  encoding = 'cp949', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 2)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>정치개혁</td>\n",
       "      <td>가정이 있는 시민에게  새벽 1시경 협박전화한 a모 구미시의원에 대해 청원합니다! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>외교_통일_국방</td>\n",
       "      <td>북한 피격 사망 공무원 사건에 대한 문재인 대통령과 정부의 합리적인 대응을 촉구합니...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>일자리</td>\n",
       "      <td>1차 긴급고용지원금이 덜 지급되었습니다. 추가근무수당 미지급을 위해 편법을 쓰는 기...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>미래</td>\n",
       "      <td>자화자찬중이신 정부님들께 한 말씀 올립니다 코로나19...‘따뜻한 눈길’ 캠페인 마...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>성장동력</td>\n",
       "      <td>기생충 제작사 ******* 조사부탁합니다. 대한민국 성장동력을 위해서 BTS를 계...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0                                                  1\n",
       "0      정치개혁  가정이 있는 시민에게  새벽 1시경 협박전화한 a모 구미시의원에 대해 청원합니다! ...\n",
       "1  외교_통일_국방  북한 피격 사망 공무원 사건에 대한 문재인 대통령과 정부의 합리적인 대응을 촉구합니...\n",
       "2       일자리  1차 긴급고용지원금이 덜 지급되었습니다. 추가근무수당 미지급을 위해 편법을 쓰는 기...\n",
       "3        미래  자화자찬중이신 정부님들께 한 말씀 올립니다 코로나19...‘따뜻한 눈길’ 캠페인 마...\n",
       "4      성장동력  기생충 제작사 ******* 조사부탁합니다. 대한민국 성장동력을 위해서 BTS를 계..."
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wc(dat):\n",
    "    for i in range(len(df)):\n",
    "        txt = dat.iloc[i][1]\n",
    "        words = get_nouns(txt)\n",
    "        result = visualize(words)\n",
    "        result.to_file(dat.iloc[i][0]+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Final Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from konlpy.tag import Komoran\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nouns(txt):\n",
    "    txt = re.sub('[-=.*#/!?:$}]', '', txt)\n",
    "    tokenizer = Komoran()\n",
    "    nouns = tokenizer.nouns(txt)\n",
    "    result = []\n",
    "    stop_words = [\"이제\", \"대해\", \"관련\", \"다시\", \"하라\", \"시오\", \"대한\", \"위해\",\n",
    "                  \"및\", \"두기\", \"저희\", \"제발\", \"바로\", \"동안\", \"정말\", \"경우\", \"제대로\", \"당장\"]\n",
    "    for w in nouns: \n",
    "        if w not in stop_words: \n",
    "            result.append(w)\n",
    "    for i,v in enumerate(result):\n",
    "        if len(v) < 2:\n",
    "            result.pop(i)\n",
    "    count = Counter(result)\n",
    "    noun_list = count.most_common(50)  \n",
    "    return noun_list\n",
    "\n",
    "def visualize(noun_list):\n",
    "    wc = WordCloud(font_path = \"./font/A옛날목욕탕L.TTF\",\n",
    "                  background_color = 'white', width=1000, height =1000, max_words= 100,max_font_size= 300)\n",
    "    wc.generate_from_frequencies(dict(noun_list))\n",
    "    return wc\n",
    "\n",
    "def wc(dat):\n",
    "    for i in range(len(df)):\n",
    "        txt = dat.iloc[i][1]\n",
    "        words = get_nouns(txt)\n",
    "        result = visualize(words)\n",
    "        result.to_file(dat.iloc[i][0]+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}